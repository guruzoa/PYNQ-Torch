{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries the application needs\n",
    "from __future__ import print_function\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries needed to use the accelerator\n",
    "import pynq.lib.dma # For using the DMA\n",
    "from pynq import Xlnk # Used for allocating contiguous arrays\n",
    "import numpy as np # Xlnk uses numpy arrays\n",
    "from pynq import Overlay # Used to download the bitstream\n",
    "import struct\n",
    "from pynq import DefaultIP # Used for AXI-Lite class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReturnValuesDriver(DefaultIP):\n",
    "    # The following class is used to retrieve data from the AXI-Lite interface\n",
    "    \n",
    "    def __init__(self, description):\n",
    "        super().__init__(description=description)\n",
    "\n",
    "    bindto = ['xilinx.com:hls:backward_lite:1.0'] # The class will be associated to the backward_lite IP in Vivado\n",
    "\n",
    "    \"\"\"The following functions represent each variable that will be returned. Simply calling these will allow us to obtain the \n",
    "     output. We use the unpack function from the struct package to be able to read floating-point numbers as by default they\n",
    "     are read as integers. The addresses from where we read (i.e. 0x10, 0x18) are taken from Vivado HLS.\"\"\"\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return struct.unpack(\"f\", struct.pack(\"I\", self.read(0x10)))[0]\n",
    "    @property\n",
    "    def w1(self):\n",
    "        return struct.unpack(\"f\", struct.pack(\"I\", self.read(0x18)))[0]\n",
    "    @property\n",
    "    def w2(self):\n",
    "        return struct.unpack(\"f\", struct.pack(\"I\", self.read(0x20)))[0]\n",
    "    @property\n",
    "    def w3(self):\n",
    "        return struct.unpack(\"f\", struct.pack(\"I\", self.read(0x28)))[0]\n",
    "    @property\n",
    "    def w4(self):\n",
    "        return struct.unpack(\"f\", struct.pack(\"I\", self.read(0x30)))[0]\n",
    "    @property\n",
    "    def w5(self):\n",
    "        return struct.unpack(\"f\", struct.pack(\"I\", self.read(0x38)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network will learn a polynomial, for which the following are taken from the example itself unless stated\n",
    "POLY_DEGREE = 5\n",
    "W_target = torch.randn(POLY_DEGREE, 1) * 5\n",
    "b_target = torch.randn(1) * 5\n",
    "\n",
    "def make_features(x):\n",
    "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
    "    # This function is one of the kernels which are executed in hardware.\n",
    "    \n",
    "    # We first perform some pre-processing\n",
    "    x = x.unsqueeze(1)\n",
    "    in_buffer[:] = x.data.numpy()[:]\n",
    "    \n",
    "    # Then, we must provide the data to the hardware through the DMA\n",
    "    dma2.sendchannel.transfer(in_buffer) # providing the inputs\n",
    "    dma2.recvchannel.transfer(out_buffer) # providing the contiguous array to where the output should be placed\n",
    "    dma2.sendchannel.wait() # Wait until the last flag is set high.\n",
    "    dma2.recvchannel.wait()\n",
    "    return torch.tensor(out_buffer) # Some post-processing to convert the numpy array to a tensor\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Approximated function.\"\"\"\n",
    "    return x.mm(W_target) + b_target.item()\n",
    "\n",
    "def poly_desc(W, b):\n",
    "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
    "    result = 'y = '\n",
    "    for i, w in enumerate(W):\n",
    "        result += '{:+.2f} x^{} '.format(w, len(W) - i)\n",
    "    result += '{:+.2f}'.format(b[0])\n",
    "    return result\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/Regression/backward_lite_features.bit') # Download the bitstream onto the FPGA\n",
    "\n",
    "# In this accelerator, we are accelerating two kernels and each has its own DMA which are assigned here:\n",
    "dma1 = overlay.axi_dma_0 # Backward\n",
    "dma2 = overlay.axi_dma_1 # Equation Matrix\n",
    "\n",
    "# Since this IP uses AXI-Lite for the output, we can associate that to a variable and then use our class defined above through \n",
    "# this\n",
    "backward_ip = overlay.backward_lite_0\n",
    "\n",
    "xlnk = Xlnk() # Used for allocation\n",
    "# Allocating the contiguous arrays of a fixed size:\n",
    "in_stream = xlnk.cma_array(shape=(32+32+(32*5),1), dtype=np.float32)\n",
    "in_buffer = xlnk.cma_array(shape=(32,1), dtype=np.float32)\n",
    "out_buffer = xlnk.cma_array(shape=(32,5), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.000680 after 12876 batches\n",
      "==> Learned function:\ty = -2.41 x^5 +0.11 x^4 -3.11 x^3 -1.80 x^2 -0.66 x^1 -1.70\n",
      "==> Actual function:\ty = -2.39 x^5 +0.19 x^4 -3.10 x^3 -1.84 x^2 -0.66 x^1 -1.70\n"
     ]
    }
   ],
   "source": [
    "fc = torch.nn.Linear(W_target.size(0), 1)\n",
    "\n",
    "for batch_idx in count(1):\n",
    "    # Get data\n",
    "    batch_x, batch_y = get_batch()\n",
    "\n",
    "    myVar = fc(batch_x)\n",
    "    # Forward pass\n",
    "    output = F.smooth_l1_loss(myVar, batch_y)\n",
    "    loss = output.item()\n",
    "\n",
    "    # Pre-processing for the other accelerator\n",
    "    batch_x_stream = batch_x.t()\n",
    "    batch_x_stream = batch_x_stream.reshape(32*5, 1)\n",
    "    in_stream[:] = torch.cat((myVar.data, batch_y.data, batch_x_stream.data), 0).numpy()[:]\n",
    "    \n",
    "    # Transfer data to the DMA\n",
    "    dma1.sendchannel.transfer(in_stream)\n",
    "    dma1.sendchannel.wait()\n",
    "        \n",
    "    # Obtaining the output from the AXI-Lite interface, as well as post-processing\n",
    "    bias_grad = torch.tensor([backward_ip.bias])\n",
    "    weight_grad = torch.tensor([[backward_ip.w1, backward_ip.w2, backward_ip.w3, backward_ip.w4, backward_ip.w5]])\n",
    "        \n",
    "    #print(weight_grad, bias_grad)\n",
    "    flag = True\n",
    "    for param in fc.parameters():\n",
    "        if (flag):\n",
    "            param.data.add_(-0.1 * weight_grad)\n",
    "            flag = False\n",
    "        else:\n",
    "            param.data.add_(-0.1 * bias_grad)\n",
    "\n",
    "    # Stop criterion\n",
    "    if loss < 1e-3:\n",
    "        break\n",
    "\n",
    "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
    "print('==> Learned function:\\t' + poly_desc(fc.weight.view(-1), fc.bias))\n",
    "print('==> Actual function:\\t' + poly_desc(W_target.view(-1), b_target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
